diff --git a/.idea/graduation3.iml b/.idea/graduation3.iml
index 707eda7..9aa7215 100644
--- a/.idea/graduation3.iml
+++ b/.idea/graduation3.iml
@@ -2,7 +2,7 @@
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$" />
-    <orderEntry type="jdk" jdkName="Python 3.6 (new)" jdkType="Python SDK" />
+    <orderEntry type="jdk" jdkName="Python 3.6 (DQEAF)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="TestRunnerService">
diff --git a/.idea/misc.xml b/.idea/misc.xml
index 9dacc81..18bd36b 100644
--- a/.idea/misc.xml
+++ b/.idea/misc.xml
@@ -3,5 +3,5 @@
   <component name="PreferredVcsStorage">
     <preferredVcsName>ApexVCS</preferredVcsName>
   </component>
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.6 (new)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.6 (DQEAF)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
diff --git a/train.py b/train.py
index f019eab..1208fd6 100644
--- a/train.py
+++ b/train.py
@@ -187,14 +187,15 @@ def main():
         q_hook = PlotHook('Average Q Value', ylabel='Average Action Value (Q)')
         loss_hook = PlotHook('Average Loss', plot_index=1, ylabel='Average Loss per Episode')
         reward_hook = PlotHook('Average Reward', plot_index=2, ylabel='Reward Value per Episode')
-        scores_hook = TrainingScoresHook('scores.txt', args.outdir)
+        # scores_hook = TrainingScoresHook('scores.txt', args.outdir)
+
         training_start_time = datetime.datetime.now()
         chainerrl.experiments.train_agent(
             agent, env,
             steps=args.steps,  # Train the graduation_agent for this many rounds steps
             max_episode_len=env.maxturns,  # Maximum length of each episodes
             outdir=args.outdir,  # Save everything to 'result' directory
-            step_hooks=[q_hook, loss_hook, scores_hook, reward_hook],
+            step_hooks=[q_hook, loss_hook, reward_hook],
             successful_score=7,
         )
         training_end_time = datetime.datetime.now()
@@ -202,7 +203,7 @@ def main():
             f.write("start_time->{}   end_time->{}\n".format(training_start_time,training_end_time))
 
         # 保证训练一轮就成功的情况下能成功打印scores.txt文件
-        scores_hook(None, None, 1000)
+        # scores_hook(None, None, 1000)
 
         return env, agent
 
